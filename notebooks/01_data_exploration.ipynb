{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration & Preparation\n",
    "\n",
    "This notebook loads the audio dataset, explores its statistics, creates DataFrames, and balances the dataset for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: ../ml_data/processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "processed_folder = Path('../ml_data/processed')\n",
    "print(f\"Loading from: {processed_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio dataset...\n",
      "Source: ../ml_data/processed\n",
      "\n",
      "Loading bike                :  654 files ... ✓ 654\n",
      "Loading bus                 : 2772 files ... ✓ 2772\n",
      "Loading car                 : 1695 files ... ✓ 1695\n",
      "Loading cng_auto            :  508 files ... ✓ 508\n",
      "Loading construction_noise  :  574 files ... ✓ 574\n",
      "Loading protest             :  879 files ... ✓ 879\n",
      "Loading siren               :  552 files ... ✓ 552\n",
      "Loading traffic_jam         :  517 files ... ✓ 517\n",
      "Loading train               :  899 files ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m audio_path \u001b[38;5;129;01min\u001b[39;00m audio_files:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# Load audio with librosa (sr=None keeps original sample rate)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         waveform, sample_rate = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         myVoices.append({\n\u001b[32m     20\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(audio_path),\n\u001b[32m     21\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m: audio_path.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(waveform) / sample_rate\n\u001b[32m     26\u001b[39m         })\n\u001b[32m     27\u001b[39m         success_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/bangladeshi-audio-ml/.venv/lib/python3.12/site-packages/librosa/core/audio.py:176\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m         y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    179\u001b[39m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[32m    180\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/bangladeshi-audio-ml/.venv/lib/python3.12/site-packages/librosa/core/audio.py:222\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    219\u001b[39m         frame_duration = -\u001b[32m1\u001b[39m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# Load the target number of frames, and transpose to match librosa form\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     y = \u001b[43msf_desc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.T\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y, sr_native\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/bangladeshi-audio-ml/.venv/lib/python3.12/site-packages/soundfile.py:942\u001b[39m, in \u001b[36mSoundFile.read\u001b[39m\u001b[34m(self, frames, dtype, always_2d, fill_value, out)\u001b[39m\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m frames < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames > \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[32m    941\u001b[39m         frames = \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mread\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) > frames:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/bangladeshi-audio-ml/.venv/lib/python3.12/site-packages/soundfile.py:1394\u001b[39m, in \u001b[36mSoundFile._array_io\u001b[39m\u001b[34m(self, action, array, frames)\u001b[39m\n\u001b[32m   1392\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m array.dtype.itemsize == _ffi.sizeof(ctype)\n\u001b[32m   1393\u001b[39m cdata = _ffi.cast(ctype + \u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m, array.__array_interface__[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/bangladeshi-audio-ml/.venv/lib/python3.12/site-packages/soundfile.py:1403\u001b[39m, in \u001b[36mSoundFile._cdata_io\u001b[39m\u001b[34m(self, action, data, ctype, frames)\u001b[39m\n\u001b[32m   1401\u001b[39m     curr = \u001b[38;5;28mself\u001b[39m.tell()\n\u001b[32m   1402\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[33m'\u001b[39m\u001b[33msf_\u001b[39m\u001b[33m'\u001b[39m + action + \u001b[33m'\u001b[39m\u001b[33mf_\u001b[39m\u001b[33m'\u001b[39m + ctype)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m frames = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1404\u001b[39m _error_check(\u001b[38;5;28mself\u001b[39m._errorcode)\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "myVoices = []\n",
    "failed_files = []\n",
    "\n",
    "print(\"Loading audio dataset...\")\n",
    "print(f\"Source: {processed_folder}\\n\")\n",
    "\n",
    "for category_folder in sorted(processed_folder.iterdir()):\n",
    "    if category_folder.is_dir():\n",
    "        category = category_folder.name\n",
    "        audio_files = list(category_folder.glob('*.wav'))\n",
    "        \n",
    "        print(f\"Loading {category:20s}: {len(audio_files):4d} files\", end=\" ... \")\n",
    "        \n",
    "        success_count = 0\n",
    "        for audio_path in audio_files:\n",
    "            try:\n",
    "                # Load audio with librosa (sr=None keeps original sample rate)\n",
    "                waveform, sample_rate = librosa.load(str(audio_path), sr=None)\n",
    "                myVoices.append({\n",
    "                    'path': str(audio_path),\n",
    "                    'filename': audio_path.name,\n",
    "                    'waveform': waveform,\n",
    "                    'sample_rate': sample_rate,\n",
    "                    'category': category,\n",
    "                    'duration': len(waveform) / sample_rate\n",
    "                })\n",
    "                success_count += 1\n",
    "            except Exception as e:\n",
    "                failed_files.append((category, audio_path.name, str(e)))\n",
    "        \n",
    "        print(f\"✓ {success_count}\")\n",
    "\n",
    "print(\"✓ Audio loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total files loaded: {len(myVoices)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"Failed to load: {len(failed_files)} files\")\n",
    "    for cat, fname, error in failed_files[:5]:  # Show first 5 errors\n",
    "        print(f\"  - {cat}/{fname}: {error}\")\n",
    "\n",
    "# Show distribution\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for cat, count in sorted(Counter([v['category'] for v in myVoices]).items()):\n",
    "    print(f\"  {cat:20s}: {count:3d} files\")\n",
    "\n",
    "# Show sample rate info\n",
    "print(f\"\\nSample Rate Distribution:\")\n",
    "sample_rates = Counter([v['sample_rate'] for v in myVoices])\n",
    "for sr, count in sorted(sample_rates.items()):\n",
    "    print(f\"  {sr:6d} Hz: {count:4d} files\")\n",
    "\n",
    "# Duration statistics\n",
    "total_duration = sum(v['duration'] for v in myVoices)\n",
    "avg_duration = total_duration / len(myVoices) if myVoices else 0\n",
    "print(f\"\\nDuration Statistics:\")\n",
    "print(f\"  Total: {total_duration/60:.2f} minutes\")\n",
    "print(f\"  Average per file: {avg_duration:.2f} seconds\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the data for the DataFrame\n",
    "df_data = []\n",
    "\n",
    "# Iterate through the myVoices list\n",
    "for audio_item in myVoices:\n",
    "    audio_path = audio_item['path']\n",
    "    waveform = audio_item['waveform']\n",
    "    sample_rate = audio_item['sample_rate']\n",
    "    category = audio_item['category']\n",
    "\n",
    "    df_data.append({\n",
    "        'audio_path': audio_path,\n",
    "        'waveform': waveform,\n",
    "        'sample_rate': sample_rate,\n",
    "        'category': category\n",
    "    })\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "myVoices_df = pd.DataFrame(df_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"DataFrame Head:\")\n",
    "display(myVoices_df.head())\n",
    "\n",
    "# Display the value counts for the 'category' column\n",
    "print(\"\\nCategory distribution:\")\n",
    "display(myVoices_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'myVoices_df' in globals() and not myVoices_df.empty:\n",
    "    # Find the minimum number of samples across all categories\n",
    "    min_samples = myVoices_df['category'].value_counts().min()\n",
    "\n",
    "    # Create an empty list to store the sampled dataframes\n",
    "    balanced_df_list = []\n",
    "\n",
    "    # Group by category and sample 'min_samples' from each group\n",
    "    for category_name, group_df in myVoices_df.groupby('category'):\n",
    "        # Use .sample() to randomly select 'min_samples' from the current category's dataframe\n",
    "        sampled_group = group_df.sample(n=min_samples, random_state=42)\n",
    "        balanced_df_list.append(sampled_group)\n",
    "\n",
    "    # Concatenate the sampled dataframes back into a single dataframe\n",
    "    balanced_myVoices_df = pd.concat(balanced_df_list).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Display the head and the new category distribution of the balanced DataFrame\n",
    "    print(\"Balanced DataFrame Head:\")\n",
    "    display(balanced_myVoices_df.head())\n",
    "\n",
    "    print(\"\\nBalanced Category Distribution:\")\n",
    "    display(balanced_myVoices_df['category'].value_counts())\n",
    "\n",
    "    print(f\"\\nOriginal number of samples: {len(myVoices_df)}\")\n",
    "    print(f\"Number of samples in the balanced DataFrame: {len(balanced_myVoices_df)}\")\n",
    "\n",
    "else:\n",
    "    print(\"The 'myVoices_df' DataFrame is not available or is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Audio Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate audio durations in seconds and extract sample rates\n",
    "audio_durations = []\n",
    "audio_sample_rates = []\n",
    "\n",
    "for item in myVoices:\n",
    "    waveform = item['waveform']\n",
    "    sample_rate = item['sample_rate']\n",
    "\n",
    "    # Duration = number of samples / sample rate\n",
    "    duration = waveform.shape[-1] / sample_rate\n",
    "    audio_durations.append(duration)\n",
    "    audio_sample_rates.append(sample_rate)\n",
    "\n",
    "print(\"Duration Statistics (first 10 files):\")\n",
    "print(f\"Audio Durations (seconds): {audio_durations[:10]}\")\n",
    "print(f\"Audio Sample Rates: {audio_sample_rates[:10]}\")\n",
    "print(f\"\\nMin duration: {min(audio_durations):.2f}s\")\n",
    "print(f\"Max duration: {max(audio_durations):.2f}s\")\n",
    "print(f\"Mean duration: {np.mean(audio_durations):.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
