{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - RNN/LSTM Model Training & Evaluation\n",
    "\n",
    "Train and evaluate LSTM-based Recurrent Neural Network for audio classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for RNN/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose features from (batch, n_mfcc, time_steps) to (batch, time_steps, n_mfcc)\n",
    "X_train_rnn = X_train.transpose(0, 2, 1)\n",
    "X_val_rnn = X_val.transpose(0, 2, 1)\n",
    "X_test_rnn = X_test.transpose(0, 2, 1)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor_rnn = torch.tensor(X_train_rnn, dtype=torch.float32)\n",
    "X_val_tensor_rnn = torch.tensor(X_val_rnn, dtype=torch.float32)\n",
    "X_test_tensor_rnn = torch.tensor(X_test_rnn, dtype=torch.float32)\n",
    "\n",
    "# Encode labels\n",
    "y_train_encoded_rnn = label_encoder.transform(y_train)\n",
    "y_val_encoded_rnn = label_encoder.transform(y_val)\n",
    "y_test_encoded_rnn = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_tensor_rnn = torch.tensor(y_train_encoded_rnn, dtype=torch.long)\n",
    "y_val_tensor_rnn = torch.tensor(y_val_encoded_rnn, dtype=torch.long)\n",
    "y_test_tensor_rnn = torch.tensor(y_test_encoded_rnn, dtype=torch.long)\n",
    "\n",
    "print(f\"✓ Data prepared\")\n",
    "print(f\"  X_train_rnn: {X_train_tensor_rnn.shape}\")\n",
    "print(f\"  X_val_rnn: {X_val_tensor_rnn.shape}\")\n",
    "print(f\"  X_test_rnn: {X_test_tensor_rnn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN/LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n",
    "        super(AudioRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer - better than simple RNN for long-term dependencies\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_size)\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: (batch, sequence_length, hidden_size)\n",
    "\n",
    "        # Use output of last time step\n",
    "        out = self.fc(self.dropout(out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "print(\"✓ RNN/LSTM model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDatasetRNN(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset_rnn = AudioDatasetRNN(X_train_tensor_rnn, y_train_tensor_rnn)\n",
    "val_dataset_rnn = AudioDatasetRNN(X_val_tensor_rnn, y_val_tensor_rnn)\n",
    "test_dataset_rnn = AudioDatasetRNN(X_test_tensor_rnn, y_test_tensor_rnn)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader_rnn = DataLoader(train_dataset_rnn, batch_size=batch_size, shuffle=True)\n",
    "val_loader_rnn = DataLoader(val_dataset_rnn, batch_size=batch_size, shuffle=False)\n",
    "test_loader_rnn = DataLoader(test_dataset_rnn, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"✓ DataLoaders created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN/LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_rnn.shape[2]  # n_mfcc\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = len(y_train.unique())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "rnn_model = AudioRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion_rnn = nn.CrossEntropyLoss()\n",
    "optimizer_rnn = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs_rnn = 20\n",
    "train_losses_rnn = []\n",
    "val_losses_rnn = []\n",
    "val_accuracies_rnn = []\n",
    "\n",
    "print(\"Starting RNN/LSTM model training...\")\n",
    "for epoch in range(num_epochs_rnn):\n",
    "    rnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_rnn:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_rnn.zero_grad()\n",
    "        outputs = rnn_model(inputs)\n",
    "        loss = criterion_rnn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_rnn.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset_rnn)\n",
    "    train_losses_rnn.append(epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    rnn_model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader_rnn:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = rnn_model(inputs)\n",
    "            loss = criterion_rnn(outputs, labels)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_dataset_rnn)\n",
    "    val_losses_rnn.append(epoch_val_loss)\n",
    "    epoch_val_accuracy = correct_predictions / total_predictions\n",
    "    val_accuracies_rnn.append(epoch_val_accuracy)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs_rnn}, Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.4f}\")\n",
    "\n",
    "print(\"✓ RNN/LSTM Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.eval()\n",
    "all_predictions_rnn = []\n",
    "all_true_labels_rnn = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_rnn:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = rnn_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_predictions_rnn.extend(predicted.tolist())\n",
    "        all_true_labels_rnn.extend(labels.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_rnn = accuracy_score(all_true_labels_rnn, all_predictions_rnn)\n",
    "precision_rnn = precision_score(all_true_labels_rnn, all_predictions_rnn, average='weighted')\n",
    "recall_rnn = recall_score(all_true_labels_rnn, all_predictions_rnn, average='weighted')\n",
    "f1_rnn = f1_score(all_true_labels_rnn, all_predictions_rnn, average='weighted')\n",
    "\n",
    "cm_rnn = confusion_matrix(all_true_labels_rnn, all_predictions_rnn)\n",
    "per_class_accuracy_rnn = cm_rnn.diagonal() / cm_rnn.sum(axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RNN/LSTM Model Evaluation Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy_rnn:.4f}\")\n",
    "print(f\"Precision: {precision_rnn:.4f}\")\n",
    "print(f\"Recall:    {recall_rnn:.4f}\")\n",
    "print(f\"F1-score:  {f1_rnn:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_rnn, annot=True, fmt='d', cmap='Oranges', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('RNN/LSTM Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_labels, per_class_accuracy_rnn, color='orange', edgecolor='darkorange')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('RNN/LSTM Per-Class Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_rnn, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_losses_rnn, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('RNN/LSTM Training History')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
